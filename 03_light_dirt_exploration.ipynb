{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7e804c-599a-4440-8b48-398b9dcb6f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export WANDB_API_KEY=\"4a8fc5b45c6c79237bcb32a9659c090b1458dde7\"\n",
    "!pip install --quiet wandb\n",
    "!pip install --quiet nvidia-dali-cuda110\n",
    "!pip install --quiet lru-dict\n",
    "!pip install --quiet efficientnet_pytorch\n",
    "!pip install --quiet pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a6c9ae2-53cc-4122-8fe7-8e932d558e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from training_wheels import TrainingWheels\n",
    "from dataset import DataloopDataset, DataloopFiles\n",
    "from augmentation import Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ccff89-1b42-4bd1-b297-95efa7e92054",
   "metadata": {},
   "source": [
    "# Checking model performance on light dirt vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c003e6b4-90d9-4bf8-93fe-be56927eb7ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'dataset_dir':\"dataloop\",\n",
    "    'model':\"resnet18\",\n",
    "    'use_wandb':True,\n",
    "    'enable_random_cropping':False,\n",
    "    'batch_size':2,\n",
    "    'num_gpus':1,\n",
    "    'downscaling_width':1224,\n",
    "    'downscaling_height':1632,\n",
    "    'max_epochs':50,\n",
    "    'accelerator':None,\n",
    "    'devices':None,\n",
    "    'use_dali':False,\n",
    "    'center_crop':448,\n",
    "    'enable_vertical_mirroring':False,\n",
    "    'enable_horizontal_mirroring':True,\n",
    "    'random_rotation_angle':15,\n",
    "    'noise_amount':0,\n",
    "    'resume_from_checkpoint':None,\n",
    "    'enable_image_logging':True,\n",
    "    'lr':0.00003,\n",
    "    'balance_sampler':False,\n",
    "    'train_sample_size':250\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d0de8fd-1675-4233-ab06-d52888d4fc3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This loads the augmentation object (see the keywords and how they are used inside )\n",
    "augmentation = Augmentation(enable_random_cropping=hparams['enable_random_cropping'],\n",
    "                            enable_vertical_mirroring=hparams['enable_vertical_mirroring'],\n",
    "                            enable_horizontal_mirroring=hparams['enable_horizontal_mirroring'],\n",
    "                            random_rotation_angle=hparams['random_rotation_angle'],\n",
    "                            noise_amount=hparams['noise_amount'],\n",
    "                            downscaling_width=hparams['downscaling_width'],\n",
    "                            downscaling_height=hparams['downscaling_height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b012b0-90ed-49a1-a5e0-6279b103bdd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_dir = hparams['dataset_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193bed09-c352-4aeb-b04f-503cb97b7fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mashley-lawrencehuizenga\u001b[0m (\u001b[33mfyusion\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/SageMaker/Car_Clean_Classifier/wandb/run-20231108_202918-jlpbrhg5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fyusion/Car_Clean_Classifier/runs/jlpbrhg5' target=\"_blank\">good-dream-5</a></strong> to <a href='https://wandb.ai/fyusion/Car_Clean_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fyusion/Car_Clean_Classifier' target=\"_blank\">https://wandb.ai/fyusion/Car_Clean_Classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fyusion/Car_Clean_Classifier/runs/jlpbrhg5' target=\"_blank\">https://wandb.ai/fyusion/Car_Clean_Classifier/runs/jlpbrhg5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-c4d6x0p0:v49, 128.86MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact('fyusion/car-condition-classifier/model-c4d6x0p0:v49', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "model = TrainingWheels.load_from_checkpoint(artifact_dir+\"/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8c3739-1cf5-4ade-b714-2bf4c6cd7dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This loads the Validation images. Note currently it's set to a specific seed so the loading should be the same each run...\n",
    "model.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3fd6474-251a-4d00-8dee-90fc70ee2a63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This saves the file list. Unfortunately, the file_names can't be grabbed unless we actually grab the image itself, \n",
    "# which takes a while\n",
    "file_list = []\n",
    "for val in iter(model.validation_data):\n",
    "    file_list+=[val[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d8dd47-e3b6-430f-8225-556557129a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting only light dirt images\n",
    "class_to_label = {\"clean\": 0, \"light_dirt\": 1, \"heavy_dirt\": 0}\n",
    "files = []\n",
    "labels = []\n",
    "file_names = []\n",
    "\n",
    "for file in file_list:\n",
    "    try:\n",
    "        target_file = os.path.join(target_dir, \"items\", file)\n",
    "        Image.open(target_file)\n",
    "        # Try to open the json file\n",
    "        annotation_file_name = os.path.join(\n",
    "            target_dir, \"json\", os.path.splitext(file)[0] + \".json\"\n",
    "        )\n",
    "        with open(annotation_file_name) as annotation_file:\n",
    "            json_data = json.load(annotation_file)\n",
    "            img_width = json_data[\"metadata\"][\"system\"][\"width\"]\n",
    "            img_height = json_data[\"metadata\"][\"system\"][\"height\"]\n",
    "            annotations = []\n",
    "            for annotation in json_data[\"annotations\"]:\n",
    "                label = annotation[\"label\"]\n",
    "                try:\n",
    "                    coords = annotation[\"coordinates\"]\n",
    "                    p1 = np.array([coords[0][\"x\"], coords[0][\"y\"]])\n",
    "                    p2 = np.array([coords[1][\"x\"], coords[1][\"y\"]])\n",
    "                    bbox_size = np.linalg.norm(p2 - p1)\n",
    "                    annotations.append(\n",
    "                        [bbox_size, class_to_label[label], coords]\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        annotations.append([1, class_to_label[label], 0])\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "            annotations = sorted(annotations, key=lambda x: x[0], reverse=True)\n",
    "            # Only the biggest bounding box is considered\n",
    "            if len(annotations) == 0:\n",
    "                continue\n",
    "            if annotations[0][1] == 1:\n",
    "                files.append(target_file)\n",
    "                labels.append(annotations[0][1])\n",
    "                file_names.append(file)\n",
    "    except FileNotFoundError:\n",
    "        # We just ignore files that are not images or do not have a json file\n",
    "        continue\n",
    "assert len(files) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8391d368-9d29-4c04-85df-065630691cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is specifically written to pull all files in a list\n",
    "valid_set = DataloopFiles(dataset_dir='dataloop',file_list=file_names,\n",
    "                          train=False,\n",
    "                          augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b662b0ec-6657-4b9d-973a-3fa6420498e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This takes a while, loading an image and scoring an image both happen here\n",
    "# Note the need for no_grad. If this isn't called memory usage goes through the roof quickly\n",
    "output_valid = []\n",
    "for val in valid_set:\n",
    "    with torch.no_grad():\n",
    "        temp = model(val[1].unsqueeze(0).to('cuda'))\n",
    "    output_valid.append(temp)\n",
    "    del temp\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b1745c0-2ec9-4a47-886b-c8eee6566178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This bit of code checks whether the Clean Val is larger than Dirt value\n",
    "list_val = []\n",
    "for j in output_valid:\n",
    "    temp = j.cpu().numpy()[0]\n",
    "    list_val.append(temp[0]>temp[1])\n",
    "    del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60140152-0277-46e4-a71b-7e210b654303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d308cd1-a4ec-4765-b551-f5a4b223b735",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af569cf3a6e84f74be41f52eb5092df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">good-dream-5</strong> at: <a href='https://wandb.ai/fyusion/Car_Clean_Classifier/runs/jlpbrhg5' target=\"_blank\">https://wandb.ai/fyusion/Car_Clean_Classifier/runs/jlpbrhg5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231108_202918-jlpbrhg5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0313a04b-f2e3-4e9b-8e1d-b463284958da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
